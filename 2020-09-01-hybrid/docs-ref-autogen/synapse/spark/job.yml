### YamlMime:AzureCLIGroup
uid: az_synapse_spark_job
name: az synapse spark job
summary: |-
  Manage Synapse Spark batch jobs.
status: GA
sourceType: Core
directCommands:
- uid: az_synapse_spark_job_cancel
  name: az synapse spark job cancel
  summary: |-
    Cancel a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job cancel --livy-id
                                --spark-pool-name
                                --workspace-name
                                [--yes]
  examples:
  - summary: |-
      Cancel a Spark job.
    syntax: az synapse spark job cancel --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: |-
      The id of the Spark job.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_synapse_spark_job_list
  name: az synapse spark job list
  summary: |-
    List all Spark jobs.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job list --spark-pool-name
                              --workspace-name
                              [--from-index]
                              [--size]
  examples:
  - summary: |-
      List all Spark jobs.
    syntax: az synapse spark job list --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --from-index
    summary: |-
      Optional parameter specifying which index the list should begin from.
  - name: --size
    summary: |-
      The size of the returned list.By default it is 20 and that is the maximum.
- uid: az_synapse_spark_job_show
  name: az synapse spark job show
  summary: |-
    Get a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job show --livy-id
                              --spark-pool-name
                              --workspace-name
  examples:
  - summary: |-
      Get a Spark job.
    syntax: az synapse spark job show --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: |-
      The id of the Spark job.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
- uid: az_synapse_spark_job_submit
  name: az synapse spark job submit
  summary: |-
    Submit a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job submit --executor-size {Large, Medium, Small}
                                --executors
                                --main-definition-file
                                --name
                                --spark-pool-name
                                --workspace-name
                                [--archives]
                                [--arguments]
                                [--configuration]
                                [--language {CSharp, PySpark, Python, Scala, Spark, SparkDotNet}]
                                [--main-class-name]
                                [--reference-files]
                                [--tags]
  examples:
  - summary: |-
      Submit a Java Spark job.
    syntax: >-
      az synapse spark job submit --name WordCount_Java --workspace-name testsynapseworkspace \

      --spark-pool-name testsparkpool \

      --main-definition-file abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/wordcount.jar \

      --main-class-name WordCount \

      --arguments abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/shakespeare.txt \

      abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/result/ \

      --executors 2 --executor-size Small
  requiredParameters:
  - isRequired: true
    name: --executor-size
    parameterValueGroup: "Large, Medium, Small"
    summary: |-
      The executor size.
  - isRequired: true
    name: --executors
    summary: |-
      The number of executors.
  - isRequired: true
    name: --main-definition-file
    summary: |-
      The main file used for the job.
  - isRequired: true
    name: --name -n
    summary: |-
      The Spark job name.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --archives
    summary: |-
      The array of archives.
  - name: --arguments
    summary: |-
      Optional arguments to the job (Note: please use storage URIs for file arguments).
  - name: --configuration
    summary: |-
      The configuration of Spark job.
  - name: --language
    defaultValue: "Scala"
    parameterValueGroup: "CSharp, PySpark, Python, Scala, Spark, SparkDotNet"
    summary: |-
      The Spark job language.
  - name: --main-class-name
    summary: |-
      The fully-qualified identifier or the main class that is in the main definition file.
  - name: --reference-files
    summary: |-
      Additional files used for reference in the main definition file.
  - name: --tags
    summary: |-
      Space-separated tags: key[=value] [key[=value] ...]. Use "" to clear existing tags.
commands:
- az_synapse_spark_job_cancel
- az_synapse_spark_job_list
- az_synapse_spark_job_show
- az_synapse_spark_job_submit
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  ms.date: 10/27/2021
  description: Manage Synapse Spark batch jobs.
