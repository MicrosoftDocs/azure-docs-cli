### YamlMime:AzureCLIGroup
uid: az_dt_job_import
name: az dt job import
extensionInformation: >-
  > [!NOTE]

  > This reference is part of the **azure-iot** extension for the Azure CLI (version 2.37.0 or higher). The extension will automatically install the first time you run an **az dt job import** command. [Learn more](https://learn.microsoft.com/cli/azure/azure-cli-extensions-overview) about extensions.
summary: |-
  Manage and configure jobs for importing model, twin and relationships data to a digital twin instance.
status: GA
sourceType: Extension
directCommands:
- uid: az_dt_job_import_cancel
  name: az dt job import cancel
  summary: |-
    Cancel a data import job executed on a digital twins instance.
  status: GA
  sourceType: Extension
  syntax: >-
    az dt job import cancel --dt-name
                            --job-id
                            [--resource-group]
                            [--yes]
  examples:
  - summary: |-
      Cancel a data import job by job id.
    syntax: az dt job import cancel -n {instance_or_hostname} -j {job_id}
  requiredParameters:
  - isRequired: true
    name: --dt-name --dtn -n
    summary: |-
      Digital Twins instance name or hostname. If an instance name is provided, the user subscription is first queried for the target instance to retrieve the hostname. If a hostname is provided, the subscription query is skipped and the provided value is used for subsequent interaction.
  - isRequired: true
    name: --job-id -j
    summary: |-
      Id of job. A system generated id is assigned when this parameter is ommitted during job creation.
  optionalParameters:
  - name: --resource-group -g
    summary: |-
      Digital Twins instance resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_dt_job_import_create
  name: az dt job import create
  summary: |-
    Create and execute a data import job on a digital twin instance.
  description: |-
    The command requires an input import data file (in .ndjson format) to be present in the input blob container. Additionally, the DT instance being used must have 'Storage Blob Data Contributor' role set on input storage account. Once the job completes, an output file containing job's logs and errors will be created.
  status: GA
  sourceType: Extension
  syntax: >-
    az dt job import create --data-file
                            --dt-name
                            --ibc
                            --input-storage-account
                            [--job-id]
                            [--obc]
                            [--of]
                            [--osa]
                            [--resource-group]
  examples:
  - summary: |-
      Creates a job for importing data file stored in an Azure Storage Container. Import job's output file is created in the input file's blob container.
    syntax: az dt job import create -n {instance_or_hostname} --data-file {data_file_name} --input-blob-container {input_blob_container_name} --input-storage-account {input_storage_account_name} --output-file {output_file_name}
  - summary: |-
      Creates a job for importing data file stored in an azure storage container. Import job's output file is created in user-defined storage account and blob container.
    syntax: az dt job import create -n {instance_or_hostname} --data-file {data_file_name} --input-blob-container {input_blob_container_name} --input-storage-account {input_storage_account_name} --output-file {output_file_name} --output-blob-container {output_blob_container_name} --output-storage-account {output_storage_account_name}
  requiredParameters:
  - isRequired: true
    name: --data-file --df
    summary: |-
      Name of data file input to the bulk import job. The file must be in 'ndjson' format. Sample input data file: https://github.com/Azure/azure-iot-cli-extension/tree/dev/docs/samples/adt-bulk-import-data-sample.ndjson.
  - isRequired: true
    name: --dt-name --dtn -n
    summary: |-
      Digital Twins instance name or hostname. If an instance name is provided, the user subscription is first queried for the target instance to retrieve the hostname. If a hostname is provided, the subscription query is skipped and the provided value is used for subsequent interaction.
  - isRequired: true
    name: --ibc --input-blob-container
    summary: |-
      Name of Azure Storage blob container which contains the bulk import data file.
  - isRequired: true
    name: --input-storage-account --isa
    summary: |-
      Name of Azure Storage account containing blob container which stores the bulk import data file.
  optionalParameters:
  - name: --job-id -j
    summary: |-
      Id of job. A system generated id is assigned when this parameter is ommitted during job creation.
  - name: --obc --output-blob-container
    summary: |-
      Name of Azure Storage blob container where the bulk import job's output file will be created. If not provided, will use the input blob container.
  - name: --of --output-file
    summary: |-
      Name of the bulk import job's output file. This file will contain logs as well as error information. The file gets created automatically once the job finishes. The file gets overwritten if it already exists. If not provided the output file is created with the name: <job_id>_output.txt.
  - name: --osa --output-storage-account
    summary: |-
      Name of Azure Storage account containing blob container where bulk import job's output file will be created. If not provided, will use the input storage account.
  - name: --resource-group -g
    summary: |-
      Digital Twins instance resource group. You can configure the default group using `az configure --defaults group=<name>`.
- uid: az_dt_job_import_delete
  name: az dt job import delete
  summary: |-
    Delete a data import job executed on a digital twins instance.
  status: GA
  sourceType: Extension
  syntax: >-
    az dt job import delete --dt-name
                            --job-id
                            [--resource-group]
                            [--yes]
  examples:
  - summary: |-
      Delete a data import job by job id.
    syntax: az dt job import delete -n {instance_or_hostname} -j {job_id}
  requiredParameters:
  - isRequired: true
    name: --dt-name --dtn -n
    summary: |-
      Digital Twins instance name or hostname. If an instance name is provided, the user subscription is first queried for the target instance to retrieve the hostname. If a hostname is provided, the subscription query is skipped and the provided value is used for subsequent interaction.
  - isRequired: true
    name: --job-id -j
    summary: |-
      Id of job. A system generated id is assigned when this parameter is ommitted during job creation.
  optionalParameters:
  - name: --resource-group -g
    summary: |-
      Digital Twins instance resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_dt_job_import_list
  name: az dt job import list
  summary: |-
    List all data import jobs executed on a digital twins instance.
  status: GA
  sourceType: Extension
  syntax: >-
    az dt job import list --dt-name
                          [--resource-group]
  examples:
  - summary: |-
      List all data import jobs on a target digital twins instance.
    syntax: az dt job import list -n {instance_or_hostname}
  requiredParameters:
  - isRequired: true
    name: --dt-name --dtn -n
    summary: |-
      Digital Twins instance name or hostname. If an instance name is provided, the user subscription is first queried for the target instance to retrieve the hostname. If a hostname is provided, the subscription query is skipped and the provided value is used for subsequent interaction.
  optionalParameters:
  - name: --resource-group -g
    summary: |-
      Digital Twins instance resource group. You can configure the default group using `az configure --defaults group=<name>`.
- uid: az_dt_job_import_show
  name: az dt job import show
  summary: |-
    Show details of a data import job executed on a digital twins instance.
  status: GA
  sourceType: Extension
  syntax: >-
    az dt job import show --dt-name
                          --job-id
                          [--resource-group]
  examples:
  - summary: |-
      Show details of a data import job by job id.
    syntax: az dt job import show -n {instance_or_hostname} -j {job_id}
  requiredParameters:
  - isRequired: true
    name: --dt-name --dtn -n
    summary: |-
      Digital Twins instance name or hostname. If an instance name is provided, the user subscription is first queried for the target instance to retrieve the hostname. If a hostname is provided, the subscription query is skipped and the provided value is used for subsequent interaction.
  - isRequired: true
    name: --job-id -j
    summary: |-
      Id of job. A system generated id is assigned when this parameter is ommitted during job creation.
  optionalParameters:
  - name: --resource-group -g
    summary: |-
      Digital Twins instance resource group. You can configure the default group using `az configure --defaults group=<name>`.
commands:
- az_dt_job_import_cancel
- az_dt_job_import_create
- az_dt_job_import_delete
- az_dt_job_import_list
- az_dt_job_import_show
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  description: Manage and configure jobs for importing model, twin and relationships data to a digital twin instance.
