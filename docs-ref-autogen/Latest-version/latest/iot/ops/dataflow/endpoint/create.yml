### YamlMime:AzureCLIGroup
uid: az_iot_ops_dataflow_endpoint_create
name: az iot ops dataflow endpoint create
extensionInformation: >-
  > [!NOTE]

  > This reference is part of the **azure-iot-ops** extension for the Azure CLI (version 2.62.0 or higher). The extension will automatically install the first time you run an **az iot ops dataflow endpoint create** command. [Learn more](https://learn.microsoft.com/cli/azure/azure-cli-extensions-overview) about extensions.
summary: |-
  Create or replace a dataflow endpoint resource.
status: GA
sourceType: Extension
directCommands:
- uid: az_iot_ops_dataflow_endpoint_create_adls
  name: az iot ops dataflow endpoint create adls
  summary: |-
    Create or replace a dataflow endpoint resource for Azure Data Lake Storage Gen2.
  description: |-
    For more information on Azure Data Lake Storage Gen2 dataflow endpoint, see
    https://aka.ms/adlsv2.
    Note: When using user assigned managed identity authentication method,
    scope will default to 'https://storage.azure.com/.default' if not
    specified by `--scope`.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create adls --instance
                                             --name
                                             --resource-group
                                             --sa --storage-account
                                             [--aud --audience]
                                             [--auth-type {AccessToken, SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                             [--cid --client-id]
                                             [--latency]
                                             [--mc --message-count]
                                             [--scope]
                                             [--secret-name]
                                             [--show-config {false, true}]
                                             [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create adls --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --storage-account mystorageaccount
  - summary: |-
      Create or replace a dataflow endpoint resource using user assigned managed identity authentication method.
    syntax: az iot ops dataflow endpoint create adls --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --storage-account mystorageaccount --client-id 425cb1e9-1247-4cbc-8cdb-1aac9b429696 --tenant-id bca45660-49a2-4bad-862a-0b9459b4b836 --scope "https://storage.azure.com/.default"
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create adls --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --storage-account mystorageaccount --latency 70 --message-count 100 --secret-name mysecret --show-config
  requiredParameters:
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - isRequired: true
    name: --sa --storage-account
    summary: |-
      The name of Azure Data Lake Storage Gen2 account.
  optionalParameters:
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "AccessToken, SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --latency -l
    defaultValue: "60"
    summary: |-
      The batching latency in seconds. Min value: 0, max value: 65535.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains SAS token.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_adx
  name: az iot ops dataflow endpoint create adx
  summary: |-
    Create or replace a dataflow endpoint resource for Azure Data Explorer.
  description: |-
    For more information on Azure Data Explorer dataflow endpoint, see https://aka.ms/aio-adx.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create adx --database --db
                                            --host
                                            --instance
                                            --name
                                            --resource-group
                                            [--aud --audience]
                                            [--auth-type {SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                            [--cid --client-id]
                                            [--latency]
                                            [--mc --message-count]
                                            [--scope]
                                            [--show-config {false, true}]
                                            [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create adx --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --database mydatabase --host "https://cluster.region.kusto.windows.net"
  - summary: |-
      Create or replace a dataflow endpoint resource using user assigned managed identity authentication method.
    syntax: az iot ops dataflow endpoint create adx --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --database mydatabase --host "https://cluster.region.kusto.windows.net" --client-id 425cb1e9-1247-4cbc-8cdb-1aac9b429696 --tenant-id bca45660-49a2-4bad-862a-0b9459b4b836
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create adx --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --database mydatabase --host "https://cluster.region.kusto.windows.net" --latency 70 --message-count 100 --audience myaudience --show-config
  requiredParameters:
  - isRequired: true
    name: --database --db
    summary: |-
      The name of the Azure Data Explorer database.
  - isRequired: true
    name: --host
    summary: |-
      Host of the Azure Data Explorer is Azure Data Explorer cluster URI. In the form of https://cluster.region.kusto.windows.net.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --latency -l
    defaultValue: "60"
    summary: |-
      The batching latency in seconds. Min value: 0, max value: 65535.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_custom-kafka
  name: az iot ops dataflow endpoint create custom-kafka
  summary: |-
    Create or replace a dataflow endpoint resource for custom kafka broker.
  description: |-
    For more information on custom kafka dataflow endpoint, see https://aka.ms/aio-custom-kafka.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create custom-kafka --hostname
                                                     --instance
                                                     --name
                                                     --port
                                                     --resource-group
                                                     [--acks {All, One, Zero}]
                                                     [--aud --audience]
                                                     [--auth-type {Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                                     [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                     [--cid --client-id]
                                                     [--cm --config-map-ref]
                                                     [--compression {Gzip, Lz4, None, Snappy}]
                                                     [--db --disable-batching {false, true}]
                                                     [--dbpc --disable-broker-props-copy {false, true}]
                                                     [--disable-tls {false, true}]
                                                     [--gid --group-id]
                                                     [--latency]
                                                     [--max-bytes --mb]
                                                     [--mc --message-count]
                                                     [--no-auth {false, true}]
                                                     [--partition-strategy --ps {Default, Property, Static, Topic}]
                                                     [--sasl-type {Plain, ScramSha256, ScramSha512}]
                                                     [--scope]
                                                     [--secret-name]
                                                     [--show-config {false, true}]
                                                     [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create custom-kafka --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mykafkabroker --port 9092
  - summary: |-
      Create or replace a dataflow endpoint resource using SASL authentication method.
    syntax: az iot ops dataflow endpoint create custom-kafka --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mykafkabroker --port 9092 --sasl-type ScramSha256 --secret-name mysecret
  - summary: |-
      Create or replace a dataflow endpoint resource with no auth.
    syntax: az iot ops dataflow endpoint create custom-kafka --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mykafkabroker --port 9092 --no-auth
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create custom-kafka --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mykafkabroker --port 9092 --disable-batching --latency 70 --max-bytes 200000 --message-count 100 --audience myaudience --config-map-ref myconfigmap --disable-tls --show-config
  requiredParameters:
  - isRequired: true
    name: --hostname
    summary: |-
      The hostname of the Kafka broker host setting.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --port
    summary: |-
      The port number of the Kafka broker host setting.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --acks
    defaultValue: "All"
    parameterValueGroup: "All, One, Zero"
    summary: |-
      Level of acknowledgment from the Kafka broker to ensure that the message sent by producer is successfully written to the topic and replicated across the Kafka cluster.
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --cm --config-map-ref
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --compression
    defaultValue: "None"
    parameterValueGroup: "Gzip, Lz4, None, Snappy"
    summary: |-
      Compression type for the messages sent to Kafka topics.
  - name: --db --disable-batching
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable batching.
  - name: --dbpc --disable-broker-props-copy
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable MQTT broker properties copy to Kafka user headers.
  - name: --disable-tls
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      The data flow uses an insecure connection to the Kafka/MQTT broker.
  - name: --gid --group-id
    summary: |-
      ID of consumer group that the data flow uses to read messages from the Kafka topic.
  - name: --latency -l
    defaultValue: "5"
    summary: |-
      The batching latency in milliseconds. Min value: 0, max value: 65535.
  - name: --max-bytes --mb
    defaultValue: "1000000"
    summary: |-
      Maximum number of bytes in a batch.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --no-auth
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      No authentication for the endpoint.
  - name: --partition-strategy --ps
    defaultValue: "Default"
    parameterValueGroup: "Default, Property, Static, Topic"
    summary: |-
      The partition handling strategy controls how messages are assigned to Kafka partitions when sending them to Kafka topics.
  - name: --sasl-type
    parameterValueGroup: "Plain, ScramSha256, ScramSha512"
    summary: |-
      The type of SASL authentication.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name of the Kubernetes secret that contains the SASL token.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_custom-mqtt
  name: az iot ops dataflow endpoint create custom-mqtt
  summary: |-
    Create or replace a dataflow endpoint resource for custom MQTT broker.
  description: |-
    For more information on custom MQTT dataflow endpoint, see https://aka.ms/aio-custom-mqtt.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create custom-mqtt --hostname
                                                    --instance
                                                    --name
                                                    --port
                                                    --resource-group
                                                    [--auth-type {ServiceAccountToken, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, X509Certificate}]
                                                    [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                    [--cid --client-id]
                                                    [--client-id-prefix]
                                                    [--cm --config-map-ref]
                                                    [--disable-tls {false, true}]
                                                    [--ka --keep-alive]
                                                    [--max-inflight-msg --mim]
                                                    [--no-auth {false, true}]
                                                    [--protocol {Mqtt, WebSockets}]
                                                    [--qos]
                                                    [--retain {Keep, Never}]
                                                    [--sami-aud --sami-audience]
                                                    [--sat-aud --sat-audience]
                                                    [--scope]
                                                    [--secret-name]
                                                    [--session-expiry]
                                                    [--show-config {false, true}]
                                                    [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create custom-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mymqttbroker --port 9092
  - summary: |-
      Create or replace a dataflow endpoint resource using Kubernetes Service Account Token authentication method.
    syntax: az iot ops dataflow endpoint create custom-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mymqttbroker --port 9092 --sat-audience myaudience --secret-name mysecret
  - summary: |-
      Create or replace a dataflow endpoint resource with no auth.
    syntax: az iot ops dataflow endpoint create custom-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mymqttbroker --port 9092 --no-auth
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create custom-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname mymqttbroker --port 9092 --client-id-prefix myclientprefix --keep-alive 100 --max-inflight-msg 60 --protocol WebSockets --qos 1 --retain Never --session-expiry 100 --cloud-event-attribute CreateOrRemap --secret-name mysecret --disable-tls --show-config
  requiredParameters:
  - isRequired: true
    name: --hostname
    summary: |-
      The hostname of the custom MQTT broker host setting.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --port
    summary: |-
      The port number of the custom MQTT broker host setting.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --auth-type
    parameterValueGroup: "ServiceAccountToken, SystemAssignedManagedIdentity, UserAssignedManagedIdentity, X509Certificate"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --client-id-prefix
    summary: |-
      The client id prefix for MQTT client. Note: Changing the client ID prefix after IoT Operations deployment might result in data loss.
  - name: --cm --config-map-ref
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --disable-tls
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      The data flow uses an insecure connection to the Kafka/MQTT broker.
  - name: --ka --keep-alive
    defaultValue: "60"
    summary: |-
      The maximum time in seconds that the data flow client can be idle before sending a PINGREQ message to the broker. Min value: 0.
  - name: --max-inflight-msg --mim
    defaultValue: "100"
    summary: |-
      The maximum number of inflight messages that the data flow MQTT client can have. Min value: 0.
  - name: --no-auth
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      No authentication for the endpoint.
  - name: --protocol
    defaultValue: "Mqtt"
    parameterValueGroup: "Mqtt, WebSockets"
    summary: |-
      Protocol to use for client connections.
  - name: --qos
    defaultValue: "1"
    summary: |-
      Quality of Service (QoS) level for the MQTT messages. Only 0 or 1 are supported.
  - name: --retain
    defaultValue: "Keep"
    parameterValueGroup: "Keep, Never"
    summary: |-
      Retain setting to specify whether the data flow should keep the retain flag on MQTT messages. Setting this ensures whether or not the remote broker has the same messages retained as the local broker.
  - name: --sami-aud --sami-audience
    summary: |-
      The audience of the system assigned managed identity.
  - name: --sat-aud --sat-audience
    summary: |-
      The audience of the Kubernetes service account token (SAT).
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains the X509 client certificate, private key corresponding to the client certificate, and intermediate certificates for the client certificate chain. Note: The certificate and private key must be in PEM format and not password protected.
  - name: --session-expiry
    defaultValue: "3600"
    summary: |-
      The session expiry interval in seconds for the data flow MQTT client. Min value: 0.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_eventgrid
  name: az iot ops dataflow endpoint create eventgrid
  summary: |-
    Create or replace a dataflow endpoint resource for Azure Event Grid.
  description: |-
    For more information on Azure Event Grid dataflow endpoint, see https://aka.ms/aio-eventgrid.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create eventgrid --hostname
                                                  --instance
                                                  --name
                                                  --resource-group
                                                  [--aud --audience]
                                                  [--auth-type {SystemAssignedManagedIdentity, UserAssignedManagedIdentity, X509Certificate}]
                                                  [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                  [--cid --client-id]
                                                  [--client-id-prefix]
                                                  [--cm --config-map-ref]
                                                  [--ka --keep-alive]
                                                  [--max-inflight-msg --mim]
                                                  [--port]
                                                  [--protocol {Mqtt, WebSockets}]
                                                  [--qos]
                                                  [--retain {Keep, Never}]
                                                  [--scope]
                                                  [--secret-name]
                                                  [--session-expiry]
                                                  [--show-config {false, true}]
                                                  [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create eventgrid --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname "namespace.region-1.ts.eventgrid.azure.net" --port 9092
  - summary: |-
      Create or replace a dataflow endpoint resource using X509 authentication method.
    syntax: az iot ops dataflow endpoint create eventgrid --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname "namespace.region-1.ts.eventgrid.azure.net" --port 9092 --secret-name mysecret
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create eventgrid --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname "namespace.region-1.ts.eventgrid.azure.net" --port 9092 --client-id-prefix myclientprefix --keep-alive 100 --max-inflight-msg 60 --protocol WebSockets --qos 1 --retain Never --session-expiry 100 --cloud-event-attribute CreateOrRemap --secret-name mysecret --config-map-ref myconfigmap --show-config
  requiredParameters:
  - isRequired: true
    name: --hostname
    summary: |-
      The hostname of the event grid namespace. Can be found in 'Http hostname' property. In the form of NAMESPACE.REGION-1.ts.eventgrid.azure.net.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "SystemAssignedManagedIdentity, UserAssignedManagedIdentity, X509Certificate"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --client-id-prefix
    summary: |-
      The client id prefix for MQTT client. Note: Changing the client ID prefix after IoT Operations deployment might result in data loss.
  - name: --cm --config-map-ref
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --ka --keep-alive
    defaultValue: "60"
    summary: |-
      The maximum time in seconds that the data flow client can be idle before sending a PINGREQ message to the broker. Min value: 0.
  - name: --max-inflight-msg --mim
    defaultValue: "100"
    summary: |-
      The maximum number of inflight messages that the data flow MQTT client can have. Min value: 0.
  - name: --port
    defaultValue: "8883"
    summary: |-
      The port number of the event grid namespace.
  - name: --protocol
    defaultValue: "Mqtt"
    parameterValueGroup: "Mqtt, WebSockets"
    summary: |-
      Protocol to use for client connections.
  - name: --qos
    defaultValue: "1"
    summary: |-
      Quality of Service (QoS) level for the MQTT messages. Only 0 or 1 are supported.
  - name: --retain
    defaultValue: "Keep"
    parameterValueGroup: "Keep, Never"
    summary: |-
      Retain setting to specify whether the data flow should keep the retain flag on MQTT messages. Setting this ensures whether or not the remote broker has the same messages retained as the local broker.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains the X509 client certificate, private key corresponding to the client certificate, and intermediate certificates for the client certificate chain. Note: The certificate and private key must be in PEM format and not password protected.
  - name: --session-expiry
    defaultValue: "3600"
    summary: |-
      The session expiry interval in seconds for the data flow MQTT client. Min value: 0.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_eventhub
  name: az iot ops dataflow endpoint create eventhub
  summary: |-
    Create or replace a dataflow endpoint resource for kafka-enabled Azure Event Hubs namespace.
  description: |-
    For more information on Azure Event Hubs dataflow endpoint, see https://aka.ms/aio-eventhub.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create eventhub --ehns --eventhub-namespace
                                                 --instance
                                                 --name
                                                 --resource-group
                                                 [--acks {All, One, Zero}]
                                                 [--aud --audience]
                                                 [--auth-type {Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                                 [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                 [--cid --client-id]
                                                 [--cm --config-map-ref]
                                                 [--compression {Gzip, Lz4, None, Snappy}]
                                                 [--db --disable-batching {false, true}]
                                                 [--dbpc --disable-broker-props-copy {false, true}]
                                                 [--gid --group-id]
                                                 [--latency]
                                                 [--max-bytes --mb]
                                                 [--mc --message-count]
                                                 [--partition-strategy --ps {Default, Property, Static, Topic}]
                                                 [--sasl-type {Plain, ScramSha256, ScramSha512}]
                                                 [--scope]
                                                 [--secret-name]
                                                 [--show-config {false, true}]
                                                 [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create eventhub --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --eventhub-namespace myeventhubnamespace
  - summary: |-
      Create or replace a dataflow endpoint resource using user assigned managed identity authentication method.
    syntax: az iot ops dataflow endpoint create eventhub --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --eventhub-namespace myeventhubnamespace --client-id 425cb1e9-1247-4cbc-8cdb-1aac9b429696 --tenant-id bca45660-49a2-4bad-862a-0b9459b4b836 --scope "https://eventhubs.azure.net/.default"
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create eventhub --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --eventhub-namespace myeventhubnamespace --acks One --compression Gzip --disable-broker-props-copy --group-id mygroupid --partition-strategy Static --max-bytes 200000 --message-count 100 --latency 70 --cloud-event-attribute CreateOrRemap --sasl-type ScramSha256 --secret-name mysecret --config-map-ref myconfigmap --show-config
  requiredParameters:
  - isRequired: true
    name: --ehns --eventhub-namespace
    summary: |-
      The name of the Event Hubs namespace.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --acks
    defaultValue: "All"
    parameterValueGroup: "All, One, Zero"
    summary: |-
      Level of acknowledgment from the Kafka broker to ensure that the message sent by producer is successfully written to the topic and replicated across the Kafka cluster.
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --cm --config-map-ref
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --compression
    defaultValue: "None"
    parameterValueGroup: "Gzip, Lz4, None, Snappy"
    summary: |-
      Compression type for the messages sent to Kafka topics.
  - name: --db --disable-batching
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable batching.
  - name: --dbpc --disable-broker-props-copy
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable MQTT broker properties copy to Kafka user headers.
  - name: --gid --group-id
    summary: |-
      ID of consumer group that the data flow uses to read messages from the Kafka topic.
  - name: --latency -l
    defaultValue: "5"
    summary: |-
      The batching latency in milliseconds. Min value: 0, max value: 65535.
  - name: --max-bytes --mb
    defaultValue: "1000000"
    summary: |-
      Maximum number of bytes in a batch.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --partition-strategy --ps
    defaultValue: "Default"
    parameterValueGroup: "Default, Property, Static, Topic"
    summary: |-
      The partition handling strategy controls how messages are assigned to Kafka partitions when sending them to Kafka topics.
  - name: --sasl-type
    parameterValueGroup: "Plain, ScramSha256, ScramSha512"
    summary: |-
      The type of SASL authentication.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains event hub connection string. Note: The secret must be in the same namespace as the Kafka data flow endpoint. The secret must have both the username and password as key-value pairs. For more information about secret format, please refer to link in command description.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_fabric-onelake
  name: az iot ops dataflow endpoint create fabric-onelake
  summary: |-
    Create or replace a dataflow endpoint resource for Microsoft Fabric OneLake.
  description: |-
    For more information on Microsoft Fabric OneLake dataflow endpoint, see https://aka.ms/fabric-onelake.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create fabric-onelake --instance
                                                       --lakehouse
                                                       --name
                                                       --path-type --pt {Files, Tables}
                                                       --resource-group
                                                       --workspace
                                                       [--aud --audience]
                                                       [--auth-type {SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                                       [--cid --client-id]
                                                       [--latency]
                                                       [--mc --message-count]
                                                       [--scope]
                                                       [--show-config {false, true}]
                                                       [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create fabric-onelake --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --lakehouse mylakehouse --workspace myworkspace --path-type Files
  - summary: |-
      Create or replace a dataflow endpoint resource using user assigned managed identity authentication method.
    syntax: az iot ops dataflow endpoint create fabric-onelake --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --lakehouse mylakehouse --workspace myworkspace --path-type Files --client-id 425cb1e9-1247-4cbc-8cdb-1aac9b429696 --tenant-id bca45660-49a2-4bad-862a-0b9459b4b836
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create fabric-onelake --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --lakehouse mylakehouse --workspace myworkspace --path-type Files --latency 70 --message-count 100 --audience myaudience --show-config
  requiredParameters:
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --lakehouse
    summary: |-
      The Microsoft Fabric lakehouse name under provided workspace.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --path-type --pt
    parameterValueGroup: "Files, Tables"
    summary: |-
      The type of path used in OneLake.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - isRequired: true
    name: --workspace
    summary: |-
      The Microsoft Fabric workspace name. Note: The default 'my workspace' isn't supported.
  optionalParameters:
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --latency -l
    defaultValue: "60"
    summary: |-
      The batching latency in seconds. Min value: 0, max value: 65535.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_fabric-realtime
  name: az iot ops dataflow endpoint create fabric-realtime
  summary: |-
    Create or replace a Microsoft Fabric Real-Time Intelligence data flow endpoint.
  description: |-
    For more information on Microsoft Fabric Real-Time Intelligence dataflow endpoint, see https://aka.ms/aio-fabric-real-time.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create fabric-realtime --host
                                                        --instance
                                                        --name
                                                        --resource-group
                                                        [--acks {All, One, Zero}]
                                                        [--aud --audience]
                                                        [--auth-type {Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity}]
                                                        [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                        [--cid --client-id]
                                                        [--cm --config-map-ref]
                                                        [--compression {Gzip, Lz4, None, Snappy}]
                                                        [--db --disable-batching {false, true}]
                                                        [--dbpc --disable-broker-props-copy {false, true}]
                                                        [--disable-tls {false, true}]
                                                        [--gid --group-id]
                                                        [--latency]
                                                        [--max-bytes --mb]
                                                        [--mc --message-count]
                                                        [--partition-strategy --ps {Default, Property, Static, Topic}]
                                                        [--sasl-type {Plain, ScramSha256, ScramSha512}]
                                                        [--scope]
                                                        [--secret-name]
                                                        [--show-config {false, true}]
                                                        [--tenant-id --tid]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create fabric-realtime --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --host "fabricrealtime.servicebus.windows.net:9093"
  - summary: |-
      Create or replace a dataflow endpoint resource using SASL authentication method.
    syntax: az iot ops dataflow endpoint create fabric-realtime --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --host "fabricrealtime.servicebus.windows.net:9093" --sasl-type ScramSha256 --secret-name mysecret
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create fabric-realtime --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --host "fabricrealtime.servicebus.windows.net:9093" --acks One --compression Gzip --group-id mygroupid --partition-strategy Static --max-bytes 200000 --cloud-event-attribute CreateOrRemap --disable-tls --show-config
  requiredParameters:
  - isRequired: true
    name: --host
    summary: |-
      Host of the Fabric real-time is the 'Bootstrap server' value. Can be found in event stream destination -- 'SAS Key Authentication' section. In the form of *.servicebus.windows.net:9093.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --acks
    defaultValue: "All"
    parameterValueGroup: "All, One, Zero"
    summary: |-
      Level of acknowledgment from the Kafka broker to ensure that the message sent by producer is successfully written to the topic and replicated across the Kafka cluster.
  - name: --aud --audience
    summary: |-
      Audience of the service to authenticate against.
  - name: --auth-type
    parameterValueGroup: "Sasl, SystemAssignedManagedIdentity, UserAssignedManagedIdentity"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --cid --client-id
    summary: |-
      The client ID of the user assigned identity.
  - name: --cm --config-map-ref
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --compression
    defaultValue: "None"
    parameterValueGroup: "Gzip, Lz4, None, Snappy"
    summary: |-
      Compression type for the messages sent to Kafka topics.
  - name: --db --disable-batching
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable batching.
  - name: --dbpc --disable-broker-props-copy
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      Disable MQTT broker properties copy to Kafka user headers.
  - name: --disable-tls
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      The data flow uses an insecure connection to the Kafka/MQTT broker.
  - name: --gid --group-id
    summary: |-
      ID of consumer group that the data flow uses to read messages from the Kafka topic.
  - name: --latency -l
    defaultValue: "5"
    summary: |-
      The batching latency in milliseconds. Min value: 0, max value: 65535.
  - name: --max-bytes --mb
    defaultValue: "1000000"
    summary: |-
      Maximum number of bytes in a batch.
  - name: --mc --message-count
    defaultValue: "100000"
    summary: |-
      Maximum number of messages in a batch. Min value: 0, max value: 4294967295.
  - name: --partition-strategy --ps
    defaultValue: "Default"
    parameterValueGroup: "Default, Property, Static, Topic"
    summary: |-
      The partition handling strategy controls how messages are assigned to Kafka partitions when sending them to Kafka topics.
  - name: --sasl-type
    parameterValueGroup: "Plain, ScramSha256, ScramSha512"
    summary: |-
      The type of SASL authentication.
  - name: --scope
    summary: |-
      Resource identifier (application ID URI) of the resource, affixed with the .default suffix.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains Connection string-primary key value. Can be found in event stream destination -- 'SAS Key Authentication' section. Note: The secret must be in the same namespace as the Kafka data flow endpoint. For more information about secret format, please refer to link in command description.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
  - name: --tenant-id --tid
    summary: |-
      The tenant ID of the user assigned identity.
- uid: az_iot_ops_dataflow_endpoint_create_local-mqtt
  name: az iot ops dataflow endpoint create local-mqtt
  summary: |-
    Create or replace a Azure IoT Operations Local MQTT dataflow endpoint.
  description: |-
    For more information on Azure IoT Operations Local MQTT dataflow endpoint, see https://aka.ms/local-mqtt-broker.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create local-mqtt --hostname
                                                   --instance
                                                   --name
                                                   --port
                                                   --resource-group
                                                   [--aud --audience]
                                                   [--auth-type {ServiceAccountToken, X509Certificate}]
                                                   [--cea --cloud-event-attribute {CreateOrRemap, Propagate}]
                                                   [--client-id-prefix]
                                                   [--cm --config-map-ref]
                                                   [--disable-tls {false, true}]
                                                   [--ka --keep-alive]
                                                   [--max-inflight-msg --mim]
                                                   [--no-auth {false, true}]
                                                   [--protocol {Mqtt, WebSockets}]
                                                   [--qos]
                                                   [--retain {Keep, Never}]
                                                   [--secret-name]
                                                   [--session-expiry]
                                                   [--show-config {false, true}]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create local-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname aio-broker --port 1883
  - summary: |-
      Create or replace a dataflow endpoint resource using X509 authentication method.
    syntax: az iot ops dataflow endpoint create local-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname aio-broker --port 1883 --secret-name mysecret
  - summary: |-
      Create or replace a dataflow endpoint resource with no auth.
    syntax: az iot ops dataflow endpoint create local-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname aio-broker --port 1883 --no-auth
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create local-mqtt --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --hostname aio-broker --port 1883 --client-id-prefix myclientprefix --keep-alive 100 --max-inflight-msg 70 --protocol WebSockets --qos 0 --retain Never --show-config
  requiredParameters:
  - isRequired: true
    name: --hostname
    summary: |-
      The hostname of the local MQTT broker.
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --port
    summary: |-
      The port number of the local MQTT broker.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --aud --audience
    summary: |-
      The audience of the Kubernetes service account token (SAT).
  - name: --auth-type
    parameterValueGroup: "ServiceAccountToken, X509Certificate"
    summary: |-
      The authentication type for the dataflow endpoint. Note: When not specified, the authentication type is determinded by other authentication parameters.
  - name: --cea --cloud-event-attribute
    defaultValue: "Propagate"
    parameterValueGroup: "CreateOrRemap, Propagate"
    summary: |-
      CloudEvent settings type to map events to cloud. Different message format are required by different setting.
  - name: --client-id-prefix
    summary: |-
      The client id prefix for MQTT client. Note: Changing the client ID prefix after IoT Operations deployment might result in data loss.
  - name: --cm --config-map-ref
    defaultValue: "azure-iot-operations-aio-ca-trust-bundle"
    summary: |-
      Config map reference for Trusted CA certificate for Kafka/MQTT endpoint. Note: This ConfigMap should contain the CA certificate in PEM format. The ConfigMap must be in the same namespace as the Kafka/MQTT data flow resource.
  - name: --disable-tls
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      The data flow uses an insecure connection to the Kafka/MQTT broker.
  - name: --ka --keep-alive
    defaultValue: "60"
    summary: |-
      The maximum time in seconds that the data flow client can be idle before sending a PINGREQ message to the broker. Min value: 0.
  - name: --max-inflight-msg --mim
    defaultValue: "100"
    summary: |-
      The maximum number of inflight messages that the data flow MQTT client can have. Min value: 0.
  - name: --no-auth
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      No authentication for the endpoint.
  - name: --protocol
    defaultValue: "Mqtt"
    parameterValueGroup: "Mqtt, WebSockets"
    summary: |-
      Protocol to use for client connections.
  - name: --qos
    defaultValue: "1"
    summary: |-
      Quality of Service (QoS) level for the MQTT messages. Only 0 or 1 are supported.
  - name: --retain
    defaultValue: "Keep"
    parameterValueGroup: "Keep, Never"
    summary: |-
      Retain setting to specify whether the data flow should keep the retain flag on MQTT messages. Setting this ensures whether or not the remote broker has the same messages retained as the local broker.
  - name: --secret-name -s
    summary: |-
      The name for the kubernetes secret that contains the X509 client certificate, private key corresponding to the client certificate, and intermediate certificates for the client certificate chain. Note: The certificate and private key must be in PEM format and not password protected.
  - name: --session-expiry
    defaultValue: "3600"
    summary: |-
      The session expiry interval in seconds for the data flow MQTT client. Min value: 0.
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
- uid: az_iot_ops_dataflow_endpoint_create_local-storage
  name: az iot ops dataflow endpoint create local-storage
  summary: |-
    Create or replace a local storage dataflow endpoint.
  description: |-
    For more information on local storage dataflow endpoint, see https://aka.ms/local-storage-endpoint.
  status: GA
  sourceType: Extension
  syntax: >-
    az iot ops dataflow endpoint create local-storage --instance
                                                      --name
                                                      --pvc-ref
                                                      --resource-group
                                                      [--show-config {false, true}]
  examples:
  - summary: |-
      Create or replace a dataflow endpoint resource with minimum input.
    syntax: az iot ops dataflow endpoint create local-storage --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --pvc-ref mypvc
  - summary: |-
      Show config for creating a dataflow endpoint resource.
    syntax: az iot ops dataflow endpoint create local-storage --name myendpoint --instance mycluster-ops-instance --resource-group myresourcegroup --pvc-ref mypvc --show-config
  requiredParameters:
  - isRequired: true
    name: --instance -i
    summary: |-
      IoT Operations instance name.
  - isRequired: true
    name: --name -n
    summary: |-
      Dataflow endpoint name.
  - isRequired: true
    name: --pvc-ref
    summary: |-
      The name of the PersistentVolumeClaim (PVC) to use for local storage. Note: The PVC must be in the same namespace as the data flow endpoint.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --show-config
    parameterValueGroup: "false, true"
    summary: |-
      Show the generated resource config instead of invoking the API with it.
commands:
- az_iot_ops_dataflow_endpoint_create_adls
- az_iot_ops_dataflow_endpoint_create_adx
- az_iot_ops_dataflow_endpoint_create_custom-kafka
- az_iot_ops_dataflow_endpoint_create_custom-mqtt
- az_iot_ops_dataflow_endpoint_create_eventgrid
- az_iot_ops_dataflow_endpoint_create_eventhub
- az_iot_ops_dataflow_endpoint_create_fabric-onelake
- az_iot_ops_dataflow_endpoint_create_fabric-realtime
- az_iot_ops_dataflow_endpoint_create_local-mqtt
- az_iot_ops_dataflow_endpoint_create_local-storage
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  description: Create or replace a dataflow endpoint resource.
