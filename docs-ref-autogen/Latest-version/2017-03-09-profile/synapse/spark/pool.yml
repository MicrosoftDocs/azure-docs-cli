### YamlMime:AzureCLIGroup
uid: az_synapse_spark_pool
name: az synapse spark pool
summary: |-
  Manage Spark pools.
status: GA
sourceType: Core
directCommands:
- uid: az_synapse_spark_pool_create
  name: az synapse spark pool create
  summary: |-
    Create a Spark pool.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool create --name
                                 --node-count
                                 --node-size {Large, Medium, None, Small, XLarge, XXLarge, XXXLarge}
                                 --resource-group
                                 --spark-version
                                 --workspace-name
                                 [--delay]
                                 [--enable-auto-pause {false, true}]
                                 [--enable-auto-scale {false, true}]
                                 [--enable-dynamic-exec {false, true}]
                                 [--max-executors]
                                 [--max-node-count]
                                 [--min-executors]
                                 [--min-node-count]
                                 [--no-wait]
                                 [--node-size-family {HardwareAcceleratedFPGA, HardwareAcceleratedGPU, MemoryOptimized, None}]
                                 [--spark-config-file-path]
                                 [--spark-events-folder]
                                 [--spark-log-folder]
                                 [--tags]
  examples:
  - summary: |-
      Create a Spark pool.
    syntax: >-
      az synapse spark pool create --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --spark-version 2.4 --node-count 3 --node-size Medium --spark-config-file-path 'path/configfile.txt'
  requiredParameters:
  - isRequired: true
    name: --name -n
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --node-count
    summary: |-
      The number of node.
  - isRequired: true
    name: --node-size
    parameterValueGroup: "Large, Medium, None, Small, XLarge, XXLarge, XXXLarge"
    summary: |-
      The level of compute power that each node in the Big Data pool has..
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - isRequired: true
    name: --spark-version
    summary: |-
      The supported Spark version is 2.4 now.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The workspace name.
  optionalParameters:
  - name: --delay
    summary: |-
      The delay time whose unit is minute.
  - name: --enable-auto-pause
    parameterValueGroup: "false, true"
    summary: |-
      The flag of enabling auto pause.
  - name: --enable-auto-scale
    parameterValueGroup: "false, true"
    summary: |-
      The flag of enabling auto scale.
  - name: --enable-dynamic-exec
    parameterValueGroup: "false, true"
    summary: |-
      Indicates whether Dynamic Executor Allocation is enabled or not.
  - name: --max-executors
    summary: |-
      The maximum number of executors alloted.
  - name: --max-node-count
    summary: |-
      The max node count.
  - name: --min-executors
    summary: |-
      The minimum number of executors alloted.
  - name: --min-node-count
    summary: |-
      The min node count.
  - name: --no-wait
    defaultValue: "False"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --node-size-family
    defaultValue: "MemoryOptimized"
    parameterValueGroup: "HardwareAcceleratedFPGA, HardwareAcceleratedGPU, MemoryOptimized, None"
    summary: |-
      The kind of nodes that the Big Data pool provides.
  - name: --spark-config-file-path
    summary: |-
      Absolute path of Spark pool properties configuration file.
  - name: --spark-events-folder
    defaultValue: "/events"
    summary: |-
      The Spark events folder.
  - name: --spark-log-folder
    defaultValue: "/logs"
    summary: |-
      The default Spark log folder.
  - name: --tags
    summary: |-
      Space-separated tags: key[=value] [key[=value] ...]. Use "" to clear existing tags.
- uid: az_synapse_spark_pool_delete
  name: az synapse spark pool delete
  summary: |-
    Delete a Spark pool.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool delete [--ids]
                                 [--name]
                                 [--no-wait]
                                 [--resource-group]
                                 [--subscription]
                                 [--workspace-name]
                                 [--yes]
  examples:
  - summary: |-
      Delete a Spark pool.
    syntax: az synapse spark pool delete --name testpool --workspace-name testsynapseworkspace --resource-group rg
  optionalParameters:
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --name -n
    summary: |-
      The name of the Spark pool.
  - name: --no-wait
    defaultValue: "False"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --workspace-name
    summary: |-
      The workspace name.
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_synapse_spark_pool_list
  name: az synapse spark pool list
  summary: |-
    List all Spark pools.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool list --resource-group
                               --workspace-name
  examples:
  - summary: |-
      List all Spark pools.
    syntax: az synapse spark pool list --workspace-name testsynapseworkspace --resource-group rg
  requiredParameters:
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The workspace name.
- uid: az_synapse_spark_pool_show
  name: az synapse spark pool show
  summary: |-
    Get a Spark pool.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool show [--ids]
                               [--name]
                               [--resource-group]
                               [--subscription]
                               [--workspace-name]
  examples:
  - summary: |-
      Get a Spark pool.
    syntax: az synapse spark pool show --name testpool --workspace-name testsynapseworkspace --resource-group rg
  optionalParameters:
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --name -n
    summary: |-
      The name of the Spark pool.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --workspace-name
    summary: |-
      The workspace name.
- uid: az_synapse_spark_pool_update
  name: az synapse spark pool update
  summary: |-
    Update the Spark pool.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool update [--delay]
                                 [--enable-auto-pause {false, true}]
                                 [--enable-auto-scale {false, true}]
                                 [--enable-dynamic-exec {false, true}]
                                 [--force {false, true}]
                                 [--ids]
                                 [--library-requirements]
                                 [--max-executors]
                                 [--max-node-count]
                                 [--min-executors]
                                 [--min-node-count]
                                 [--name]
                                 [--no-wait]
                                 [--node-count]
                                 [--node-size {Large, Medium, None, Small, XLarge, XXLarge, XXXLarge}]
                                 [--package]
                                 [--package-action {Add, Remove}]
                                 [--resource-group]
                                 [--spark-config-file-path]
                                 [--subscription]
                                 [--tags]
                                 [--workspace-name]
  examples:
  - summary: |-
      Update the Spark pool's tags.
    syntax: >-
      az synapse spark pool update --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --tags key1=value1
  - summary: |-
      Update the Spark pool's auto scale configuration.
    syntax: >-
      az synapse spark pool update --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --enable-auto-scale --min-node-count 3 --max-node-count 100
  - summary: |-
      Update the Spark pool's custom libraries.
    syntax: >-
      az synapse spark pool update --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --package-action Add --package package1.jar package2.jar
  - summary: |-
      Update the Spark pool's configuration file.
    syntax: >-
      az synapse spark pool update --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --spark-config-file-path 'path/configfile.txt'
  - summary: |-
      Update the Spark pool's dynamic executor allocation configuration.
    syntax: >-
      az synapse spark pool update --name testpool --workspace-name testsynapseworkspace --resource-group rg \

      --enable-dynamic-exec --min-executors 3 --max-executors 10
  optionalParameters:
  - name: --delay
    summary: |-
      The delay time whose unit is minute.
  - name: --enable-auto-pause
    parameterValueGroup: "false, true"
    summary: |-
      The flag of enabling auto pause.
  - name: --enable-auto-scale
    parameterValueGroup: "false, true"
    summary: |-
      The flag of enabling auto scale.
  - name: --enable-dynamic-exec
    parameterValueGroup: "false, true"
    summary: |-
      Indicates whether Dynamic Executor Allocation is enabled or not.
  - name: --force
    defaultValue: "False"
    parameterValueGroup: "false, true"
    summary: |-
      The flag of force operation.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --library-requirements
    summary: |-
      The library requirements file.
  - name: --max-executors
    summary: |-
      The maximum number of executors alloted.
  - name: --max-node-count
    summary: |-
      The max node count.
  - name: --min-executors
    summary: |-
      The minimum number of executors alloted.
  - name: --min-node-count
    summary: |-
      The min node count.
  - name: --name -n
    summary: |-
      The name of the Spark pool.
  - name: --no-wait
    defaultValue: "False"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --node-count
    summary: |-
      The number of node.
  - name: --node-size
    parameterValueGroup: "Large, Medium, None, Small, XLarge, XXLarge, XXXLarge"
    summary: |-
      The level of compute power that each node in the Big Data pool has..
  - name: --package
    summary: |-
      List of workspace packages name.
  - name: --package-action
    parameterValueGroup: "Add, Remove"
    summary: |-
      Package action must be specified when you add or remove a workspace package from a Apache Spark pool.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --spark-config-file-path
    summary: |-
      Absolute path of Spark pool properties configuration file.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --tags
    summary: |-
      Space-separated tags: key[=value] [key[=value] ...]. Use "" to clear existing tags.
  - name: --workspace-name
    summary: |-
      The workspace name.
- uid: az_synapse_spark_pool_wait
  name: az synapse spark pool wait
  summary: |-
    Place the CLI in a waiting state until a condition of a Spark pool is met.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark pool wait --big-data-pool-name
                               [--created]
                               [--custom]
                               [--deleted]
                               [--exists]
                               [--ids]
                               [--interval]
                               [--resource-group]
                               [--subscription]
                               [--timeout]
                               [--updated]
                               [--workspace-name]
  requiredParameters:
  - isRequired: true
    name: --big-data-pool-name
    summary: |-
      Big Data pool name.
  optionalParameters:
  - name: --created
    defaultValue: "False"
    summary: |-
      Wait until created with 'provisioningState' at 'Succeeded'.
  - name: --custom
    summary: |-
      Wait until the condition satisfies a custom JMESPath query. E.g. provisioningState!='InProgress', instanceView.statuses[?code=='PowerState/running'].
  - name: --deleted
    defaultValue: "False"
    summary: |-
      Wait until deleted.
  - name: --exists
    defaultValue: "False"
    summary: |-
      Wait until the resource exists.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --interval
    defaultValue: "30"
    summary: |-
      Polling interval in seconds.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --timeout
    defaultValue: "3600"
    summary: |-
      Maximum wait in seconds.
  - name: --updated
    defaultValue: "False"
    summary: |-
      Wait until updated with provisioningState at 'Succeeded'.
  - name: --workspace-name
    summary: |-
      The workspace name.
commands:
- az_synapse_spark_pool_create
- az_synapse_spark_pool_delete
- az_synapse_spark_pool_list
- az_synapse_spark_pool_show
- az_synapse_spark_pool_update
- az_synapse_spark_pool_wait
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  ms.date: 10/27/2021
  description: Manage Spark pools.
