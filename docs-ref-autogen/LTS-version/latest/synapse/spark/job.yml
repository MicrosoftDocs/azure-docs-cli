### YamlMime:AzureCLIGroup
uid: az_synapse_spark_job
name: az synapse spark job
summary: |-
  Manage Synapse Spark batch jobs.
status: GA
sourceType: Core
directCommands:
- uid: az_synapse_spark_job_cancel
  name: az synapse spark job cancel
  summary: |-
    Cancel a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job cancel --livy-id
                                --spark-pool-name
                                --workspace-name
                                [--yes]
  examples:
  - summary: |-
      Cancel a Spark job.
    syntax: az synapse spark job cancel --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: |-
      The id of the Spark job.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_synapse_spark_job_list
  name: az synapse spark job list
  summary: |-
    List all Spark jobs.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job list --spark-pool-name
                              --workspace-name
                              [--from-index]
                              [--size]
  examples:
  - summary: |-
      List all Spark jobs.
    syntax: az synapse spark job list --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --from-index
    summary: |-
      Optional parameter specifying which index the list should begin from.
  - name: --size
    summary: |-
      The size of the returned list.By default it is 20 and that is the maximum.
- uid: az_synapse_spark_job_show
  name: az synapse spark job show
  summary: |-
    Get a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job show --livy-id
                              --spark-pool-name
                              --workspace-name
  examples:
  - summary: |-
      Get a Spark job.
    syntax: az synapse spark job show --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: |-
      The id of the Spark job.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
- uid: az_synapse_spark_job_submit
  name: az synapse spark job submit
  summary: |-
    Submit a Spark job.
  status: GA
  sourceType: Core
  editLink: https://github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/synapse/_help.py
  syntax: >-
    az synapse spark job submit --executor-size {Large, Medium, Small}
                                --executors
                                --main-definition-file
                                --name
                                --spark-pool-name
                                --workspace-name
                                [--archives]
                                [--arguments]
                                [--configuration]
                                [--language {CSharp, PySpark, Python, Scala, Spark, SparkDotNet}]
                                [--main-class-name]
                                [--python-files]
                                [--reference-files]
                                [--tags]
  examples:
  - summary: |-
      Submit a Java Spark job.
    syntax: >-
      az synapse spark job submit --name WordCount_Java --workspace-name testsynapseworkspace \

      --spark-pool-name testsparkpool \

      --main-definition-file abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/wordcount.jar \

      --main-class-name WordCount \

      --arguments abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/shakespeare.txt \

      abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/result/ \

      --executors 2 --executor-size Small
  requiredParameters:
  - isRequired: true
    name: --executor-size
    parameterValueGroup: "Large, Medium, Small"
    summary: |-
      The executor size.
  - isRequired: true
    name: --executors
    summary: |-
      The number of executors.
  - isRequired: true
    name: --main-definition-file
    summary: |-
      The main file used for the job.
  - isRequired: true
    name: --name -n
    summary: |-
      The Spark job name.
  - isRequired: true
    name: --spark-pool-name
    summary: |-
      The name of the Spark pool.
  - isRequired: true
    name: --workspace-name
    summary: |-
      The name of the workspace.
  optionalParameters:
  - name: --archives
    summary: |-
      The array of archives.
  - name: --arguments
    summary: |-
      Optional arguments to the job (Note: please use storage URIs for file arguments).
  - name: --configuration
    summary: |-
      The configuration of Spark job.
  - name: --language
    defaultValue: "Scala"
    parameterValueGroup: "CSharp, PySpark, Python, Scala, Spark, SparkDotNet"
    summary: |-
      The Spark job language.
  - name: --main-class-name
    summary: |-
      The fully-qualified identifier or the main class that is in the main definition file.
  - name: --python-files
    summary: |-
      The array of files used for refenence in the main python definition file.  Examples include custom whl files and custom python files.  May pass multiple files such as "az synapse spark job sumbit <other_args> --python_files abfss://file1 abss://file2".
  - name: --reference-files
    summary: |-
      Additional files used for reference in the main definition file.
  - name: --tags
    summary: |-
      Space-separated tags: key[=value] [key[=value] ...]. Use "" to clear existing tags.
commands:
- az_synapse_spark_job_cancel
- az_synapse_spark_job_list
- az_synapse_spark_job_show
- az_synapse_spark_job_submit
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  ms.date: 10/27/2021
  description: Manage Synapse Spark batch jobs.
