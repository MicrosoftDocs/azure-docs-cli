### YamlMime:AzureCLIGroup
uid: az_hdinsight-on-aks_cluster
name: az hdinsight-on-aks cluster
extensionInformation: >-
  > [!NOTE]

  > This reference is part of the **hdinsightonaks** extension for the Azure CLI (version 2.57.0 or higher). The extension will automatically install the first time you run an **az hdinsight-on-aks cluster** command. [Learn more](https://learn.microsoft.com/cli/azure/azure-cli-extensions-overview) about extensions.
summary: |-
  Cluster operations.
status: Preview
isPreview: true
previewOrExperimentalInfo: 'This command group is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus'
sourceType: Extension
directCommands:
- uid: az_hdinsight-on-aks_cluster_create
  name: az hdinsight-on-aks cluster create
  summary: |-
    Create a cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster create --cluster-name
                                       --cluster-pool-name
                                       --resource-group
                                       [--application-log-std-error-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--application-log-std-out-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--assigned-identity-client-id]
                                       [--assigned-identity-id]
                                       [--assigned-identity-object-id]
                                       [--authorization-group-id]
                                       [--authorization-user-id]
                                       [--autoscale-profile-graceful-decommission-timeout]
                                       [--autoscale-profile-type {LoadBased, ScheduleBased}]
                                       [--availability-zones]
                                       [--cluster-type]
                                       [--cluster-version]
                                       [--cooldown-period]
                                       [--coord-debug-port]
                                       [--coord-debug-suspend {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--coordinator-debug-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--coordinator-high-availability-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--db-connection-authentication-mode {IdentityAuth, SqlAuth}]
                                       [--deployment-mode {Application, Session}]
                                       [--enable-autoscale {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-la-metrics {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-log-analytics {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-prometheu {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-worker-debug {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--flink-db-auth-mode {IdentityAuth, SqlAuth}]
                                       [--flink-hive-catalog-db-connection-password-secret]
                                       [--flink-hive-catalog-db-connection-url]
                                       [--flink-hive-catalog-db-connection-user-name]
                                       [--flink-storage-key]
                                       [--flink-storage-uri]
                                       [--history-server-cpu]
                                       [--history-server-memory]
                                       [--identity-list]
                                       [--internal-ingress {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--job-manager-cpu]
                                       [--job-manager-memory]
                                       [--job-spec]
                                       [--kafka-profile]
                                       [--key-vault-id]
                                       [--llap-profile]
                                       [--loadbased-config-max-nodes]
                                       [--loadbased-config-min-nodes]
                                       [--loadbased-config-poll-interval]
                                       [--loadbased-config-scaling-rules]
                                       [--location]
                                       [--no-wait {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--nodes]
                                       [--num-replicas]
                                       [--oss-version]
                                       [--ranger-plugin-profile]
                                       [--ranger-profile]
                                       [--schedule-based-config-default-count]
                                       [--schedule-based-config-schedule]
                                       [--schedule-based-config-time-zone]
                                       [--script-action-profiles]
                                       [--secret-reference]
                                       [--service-configs]
                                       [--spark-hive-catalog-db-name]
                                       [--spark-hive-catalog-db-password-secret]
                                       [--spark-hive-catalog-db-server-name]
                                       [--spark-hive-catalog-db-user-name]
                                       [--spark-hive-catalog-key-vault-id]
                                       [--spark-hive-catalog-thrift-url]
                                       [--spark-storage-url]
                                       [--ssh-profile-count]
                                       [--stub-profile]
                                       [--tags]
                                       [--task-manager-cpu]
                                       [--task-manager-memory]
                                       [--trino-hive-catalog]
                                       [--trino-plugins-spec]
                                       [--trino-profile-user-plugins-telemetry-spec]
                                       [--user-plugins-spec]
                                       [--vm-size]
                                       [--worker-debug-port]
                                       [--worker-debug-suspend {0, 1, f, false, n, no, t, true, y, yes}]
  examples:
  - summary: |-
      Create a simple Trino cluster.
    syntax: az az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type trino --cluster-version {1.2.0} --oss-version {0.440.0} --node '[{"count":2,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000"
  - summary: |-
      Create a simple Flink cluster.
    syntax: az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type flink --flink-storage-uri {abfs://container@yourstorage.dfs.core.windows.net/} --cluster-version {1.2.0} --oss-version {1.17.0} --node '[{"count":5,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000" --job-manager-cpu {1} --job-manager-memory {2000} --task-manager-cpu {6} --task-manager-memory {49016}
  - summary: |-
      Create a simple Spark cluster.
    syntax: az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type spark --spark-storage-url {abfs://container@yourstorage.dfs.core.windows.net/} --cluster-version {1.2.0} --oss-version {3.4.1} --node '[{"count":2,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000"
  - summary: |-
      Create a simple Kafka cluster.
    syntax: az az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type kafka --cluster-version {1.2.0} --oss-version {3.6.0} --node '[{"count":2,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000" --kafka-profile '{"disk-storage":{"data-disk-size":8,"data-disk-type":"Standard_SSD_LRS"}}'
  - summary: |-
      Create a Spark cluster with custom hive metastore.
    syntax: az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type spark --spark-storage-url {abfs://container@yourstorage.dfs.core.windows.net/} --cluster-version {1.2.0} --oss-version {3.4.1} --node '[{"count":2,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000"  --secret-reference '[{reference-name:sqlpassword,secret-name:sqlpassword,type:Secret}]' --key-vault-id /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.KeyVault/vaults/CLIKV --spark-hive-kv-id /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.KeyVault/vaults/CLIKV --spark-db-auth-mode SqlAuth --spark-hive-db-name {sparkhms} --spark-hive-db-secret {sqlpassword} --spark-hive-db-server {yourserver.database.windows.net} --spark-hive-db-user {username}
  - summary: |-
      Create a Flink cluster with availability zones.
    syntax: az hdinsight-on-aks cluster create -n {clustername} --cluster-pool-name {clusterpoolname} -g {resourcesGroup} -l {location}--cluster-type flink --flink-storage-uri {abfs://container@yourstorage.dfs.core.windows.net/} --cluster-version {1.2.0} --oss-version {1.17.0} --node '[{"count":5,"type":"worker","vm-size":"Standard_D8d_v5"}]' --identity-list '[{"client-id":"00000000-0000-0000-0000-000000000000","object-id":"00000000-0000-0000-0000-000000000000","resource-id":"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/resourcesGroup/providers/Microsoft.ManagedIdentity/userAssignedIdentities/yourmsi","type":"cluster"}]' --authorization-user-id "00000000-0000-0000-0000-000000000000" --job-manager-cpu {1} --job-manager-memory {2000} --task-manager-cpu {6} --task-manager-memory {49016} --availability-zones [1,2]
  requiredParameters:
  - isRequired: true
    name: --cluster-name --name -n
    summary: |-
      The name of the HDInsight cluster.
  - isRequired: true
    name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --application-log-std-error-enabled --enable-log-std-error
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if application standard error is enabled, otherwise false.
  - name: --application-log-std-out-enabled --enable-log-std-out
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if application standard out is enabled, otherwise false.
  - name: --assigned-identity-client-id --msi-client-id
    summary: |-
      ClientId of the MSI.
  - name: --assigned-identity-id --msi-id
    summary: |-
      ResourceId of the MSI.
  - name: --assigned-identity-object-id --msi-object-id
    summary: |-
      ObjectId of the MSI.
  - name: --authorization-group-id
    summary: |-
      AAD group Ids authorized for data plane access.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --authorization-user-id
    summary: |-
      AAD user Ids authorized for data plane access.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --autoscale-profile-graceful-decommission-timeout --decommission-time
    summary: |-
      This property is for graceful decommission timeout; It has a default setting of 3600 seconds before forced shutdown takes place. This is the maximal time to wait for running containers and applications to complete before transition a DECOMMISSIONING node into DECOMMISSIONED. The default value is 3600 seconds. Negative value (like -1) is handled as infinite timeout.
  - name: --autoscale-profile-type
    parameterValueGroup: "LoadBased, ScheduleBased"
    summary: |-
      User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.
  - name: --availability-zones
    summary: |-
      The list of Availability zones to use for AKS VMSS nodes.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --cluster-type
    summary: |-
      The type of cluster.
  - name: --cluster-version
    summary: |-
      Version with 3/4 part.
  - name: --cooldown-period --loadbased-config-cooldown-period
    summary: |-
      This is a cool down period, this is a time period in seconds, which determines the amount of time that must elapse between a scaling activity started by a rule and the start of the next scaling activity, regardless of the rule that triggers it. The default value is 300 seconds.
  - name: --coord-debug-port --coordinator-debug-port
    summary: |-
      The flag that if enable debug or not. Default: 8008.
  - name: --coord-debug-suspend --coordinator-debug-suspend
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if suspend debug or not. Default: false.
  - name: --coordinator-debug-enabled --enable-coord-debug
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.
  - name: --coordinator-high-availability-enabled --enable-coord-ha
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.
  - name: --db-connection-authentication-mode --spark-db-auth-mode
    parameterValueGroup: "IdentityAuth, SqlAuth"
    summary: |-
      The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization.
  - name: --deployment-mode
    parameterValueGroup: "Application, Session"
    summary: |-
      A string property that indicates the deployment mode of Flink cluster. It can have one of the following enum values => Application, Session. Default value is Session.
  - name: --enable-autoscale
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      This indicates whether auto scale is enabled on HDInsight on AKS cluster.
  - name: --enable-la-metrics --log-analytic-profile-metrics-enabled
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if metrics are enabled, otherwise false.
  - name: --enable-log-analytics
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if log analytics is enabled for the cluster, otherwise false.
  - name: --enable-prometheu
    defaultValue: "False"
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Enable Prometheus for cluster or not.
  - name: --enable-worker-debug
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if trino cluster enable debug or not. Default: false.
  - name: --flink-db-auth-mode --metastore-db-connection-authentication-mode
    parameterValueGroup: "IdentityAuth, SqlAuth"
    summary: |-
      The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization.
  - name: --flink-hive-catalog-db-connection-password-secret --flink-hive-db-secret
    summary: |-
      Secret reference name from secretsProfile.secrets containing password for database connection.
  - name: --flink-hive-catalog-db-connection-url --flink-hive-db-url
    summary: |-
      Connection string for hive metastore database.
  - name: --flink-hive-catalog-db-connection-user-name --flink-hive-db-user
    summary: |-
      User name for database connection.
  - name: --flink-storage-key
    summary: |-
      Storage key is only required for wasb(s) storage.
  - name: --flink-storage-uri
    summary: |-
      Storage account uri which is used for savepoint and checkpoint state.
  - name: --history-server-cpu
    summary: |-
      History server CPU count.
  - name: --history-server-memory
    summary: |-
      History server memory size.
  - name: --identity-list
    summary: |-
      The list of managed identity.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --internal-ingress --internal-ingress-enabled
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Whether to create cluster using private IP instead of public IP. This property must be set at create time.
  - name: --job-manager-cpu
    summary: |-
      Job manager CPU count.
  - name: --job-manager-memory
    summary: |-
      Job manager memory size.
  - name: --job-spec
    summary: |-
      Job specifications for flink clusters in application deployment mode. The specification is immutable even if job properties are changed by calling the RunJob API, please use the ListJob API to get the latest job information.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --kafka-profile
    summary: |-
      Kafka cluster profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --key-vault-id
    summary: |-
      Name of the user Key Vault where all the cluster specific user secrets are stored.
  - name: --llap-profile
    summary: |-
      LLAP cluster profile.  Support json-file and yaml-file.
  - name: --loadbased-config-max-nodes --loadbased-max-nodes
    summary: |-
      User needs to set the maximum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.
  - name: --loadbased-config-min-nodes --loadbased-min-nodes
    summary: |-
      User needs to set the minimum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.
  - name: --loadbased-config-poll-interval --loadbased-interval
    summary: |-
      User can specify the poll interval, this is the time period (in seconds) after which scaling metrics are polled for triggering a scaling operation.
  - name: --loadbased-config-scaling-rules --loadbased-rules
    summary: |-
      The scaling rules.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --location -l
    summary: |-
      The geo-location where the resource lives  When not specified, the location of the resource group will be used.
  - name: --no-wait
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --nodes
    summary: |-
      The nodes definitions.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --num-replicas
    summary: |-
      The number of task managers.
  - name: --oss-version
    summary: |-
      Version with three part.
  - name: --ranger-plugin-profile
    summary: |-
      Cluster Ranger plugin profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --ranger-profile
    summary: |-
      The ranger cluster profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --schedule-based-config-default-count --schedule-default-count
    summary: |-
      Setting default node count of current schedule configuration. Default node count specifies the number of nodes which are default when an specified scaling operation is executed (scale up/scale down).
  - name: --schedule-based-config-schedule --schedule-schedules
    summary: |-
      This specifies the schedules where scheduled based Autoscale to be enabled, the user has a choice to set multiple rules within the schedule across days and times (start/end).  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --schedule-based-config-time-zone --schedule-time-zone
    summary: |-
      User has to specify the timezone on which the schedule has to be set for schedule based autoscale configuration.
  - name: --script-action-profiles
    summary: |-
      The script action profile list.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --secret-reference
    summary: |-
      Properties of Key Vault secret.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --service-configs --service-configs-profiles
    summary: |-
      The service configs profiles.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --spark-hive-catalog-db-name --spark-hive-db-name
    summary: |-
      The database name.
  - name: --spark-hive-catalog-db-password-secret --spark-hive-db-secret
    summary: |-
      The secret name which contains the database user password.
  - name: --spark-hive-catalog-db-server-name --spark-hive-db-server
    summary: |-
      The database server host.
  - name: --spark-hive-catalog-db-user-name --spark-hive-db-user
    summary: |-
      The database user name.
  - name: --spark-hive-catalog-key-vault-id --spark-hive-kv-id
    summary: |-
      The key vault resource id.
  - name: --spark-hive-catalog-thrift-url --spark-hive-thrift-url
    summary: |-
      The thrift url.
  - name: --spark-storage-url
    summary: |-
      The default storage URL.
  - name: --ssh-profile-count
    summary: |-
      Number of ssh pods per cluster.
  - name: --stub-profile
    summary: |-
      Stub cluster profile.  Support json-file and yaml-file.
  - name: --tags
    summary: |-
      Resource tags.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --task-manager-cpu
    summary: |-
      Task manager CPU count.
  - name: --task-manager-memory
    summary: |-
      The task manager memory size.
  - name: --trino-hive-catalog
    summary: |-
      Trino cluster hive catalog options.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --trino-plugins-spec --trino-profile-user-plugins-plugin-spec
    summary: |-
      Trino user plugins spec  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --trino-profile-user-plugins-telemetry-spec --trino-telemetry-spec
    summary: |-
      Trino user telemetry spec.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --user-plugins-spec
    summary: |-
      Spark user plugins spec  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --vm-size
    summary: |-
      The virtual machine SKU.
  - name: --worker-debug-port
    summary: |-
      The debug port. Default: 8008.
  - name: --worker-debug-suspend
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if trino cluster suspend debug or not. Default: false.
- uid: az_hdinsight-on-aks_cluster_delete
  name: az hdinsight-on-aks cluster delete
  summary: |-
    Delete a cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster delete [--cluster-name]
                                       [--cluster-pool-name]
                                       [--ids]
                                       [--no-wait {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--resource-group]
                                       [--subscription]
                                       [--yes]
  examples:
  - summary: |-
      Delete a cluster.
    syntax: az hdinsight-on-aks cluster delete  -n {clusterName} --cluster-pool-name {poolName} -g {RG}
  optionalParameters:
  - name: --cluster-name --name -n
    summary: |-
      The name of the HDInsight cluster.
  - name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --no-wait
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --yes -y
    defaultValue: "False"
    summary: |-
      Do not prompt for confirmation.
- uid: az_hdinsight-on-aks_cluster_list
  name: az hdinsight-on-aks cluster list
  summary: |-
    List the HDInsight cluster pools under a resource group.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster list --cluster-pool-name
                                     --resource-group
                                     [--max-items]
                                     [--next-token]
  examples:
  - summary: |-
      List all cluster in a cluster pool.
    syntax: az hdinsight-on-aks cluster list --cluster-pool-name {poolName}-g {RG}
  requiredParameters:
  - isRequired: true
    name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --max-items
    summary: |-
      Total number of items to return in the command's output. If the total number of items available is more than the value specified, a token is provided in the command's output. To resume pagination, provide the token value in `--next-token` argument of a subsequent command.
  - name: --next-token
    summary: |-
      Token to specify where to start paginating. This is the token value from a previously truncated response.
- uid: az_hdinsight-on-aks_cluster_list-service-config
  name: az hdinsight-on-aks cluster list-service-config
  summary: |-
    List the config dump of all services running in cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster list-service-config --cluster-name
                                                    --cluster-pool-name
                                                    --resource-group
                                                    [--max-items]
                                                    [--next-token]
  examples:
  - summary: |-
      Lists the config dump of all services running in cluster.
    syntax: az hdinsight-on-aks cluster list-service-config  --cluster-name {clusterName} --cluster-pool-name {poolName}-g {RG}
  requiredParameters:
  - isRequired: true
    name: --cluster-name
    summary: |-
      The name of the HDInsight cluster.
  - isRequired: true
    name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - isRequired: true
    name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  optionalParameters:
  - name: --max-items
    summary: |-
      Total number of items to return in the command's output. If the total number of items available is more than the value specified, a token is provided in the command's output. To resume pagination, provide the token value in `--next-token` argument of a subsequent command.
  - name: --next-token
    summary: |-
      Token to specify where to start paginating. This is the token value from a previously truncated response.
- uid: az_hdinsight-on-aks_cluster_resize
  name: az hdinsight-on-aks cluster resize
  summary: |-
    Resize an existing Cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster resize [--cluster-name]
                                       [--cluster-pool-name]
                                       [--ids]
                                       [--location]
                                       [--no-wait {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--resource-group]
                                       [--subscription]
                                       [--tags]
                                       [--target-worker-node-count]
  examples:
  - summary: |-
      Resize a cluster.
    syntax: az hdinsight-on-aks cluster resize --cluster-name {clusterName} --cluster-pool-name {poolName}-g {RG} -l {westus3} --target-worker-node-count {6}
  optionalParameters:
  - name: --cluster-name
    summary: |-
      The name of the HDInsight cluster.
  - name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --location -l
    summary: |-
      The geo-location where the resource lives  When not specified, the location of the resource group will be used.
  - name: --no-wait
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --tags
    summary: |-
      Resource tags.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --target-worker-node-count --worker-node-count
    summary: |-
      Target node count of worker node.
- uid: az_hdinsight-on-aks_cluster_show
  name: az hdinsight-on-aks cluster show
  summary: |-
    Get a HDInsight cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster show [--cluster-name]
                                     [--cluster-pool-name]
                                     [--ids]
                                     [--resource-group]
                                     [--subscription]
  examples:
  - summary: |-
      Get a cluster with cluster name.
    syntax: az hdinsight-on-aks cluster show  -n {clusterName} --cluster-pool-name {poolName} -g {RG}
  optionalParameters:
  - name: --cluster-name --name -n
    summary: |-
      The name of the HDInsight cluster.
  - name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- uid: az_hdinsight-on-aks_cluster_update
  name: az hdinsight-on-aks cluster update
  summary: |-
    Update a cluster.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster update [--add]
                                       [--application-log-std-error-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--application-log-std-out-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--assigned-identity-client-id]
                                       [--assigned-identity-id]
                                       [--assigned-identity-object-id]
                                       [--authorization-group-id]
                                       [--authorization-user-id]
                                       [--autoscale-profile-graceful-decommission-timeout]
                                       [--autoscale-profile-type {LoadBased, ScheduleBased}]
                                       [--availability-zones]
                                       [--cluster-name]
                                       [--cluster-pool-name]
                                       [--cluster-version]
                                       [--cooldown-period]
                                       [--coord-debug-port]
                                       [--coord-debug-suspend {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--coordinator-debug-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--coordinator-high-availability-enabled {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--db-connection-authentication-mode {IdentityAuth, SqlAuth}]
                                       [--deployment-mode {Application, Session}]
                                       [--enable-autoscale {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-la-metrics {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-log-analytics {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-prometheu {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--enable-worker-debug {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--flink-db-auth-mode {IdentityAuth, SqlAuth}]
                                       [--flink-hive-catalog-db-connection-password-secret]
                                       [--flink-hive-catalog-db-connection-url]
                                       [--flink-hive-catalog-db-connection-user-name]
                                       [--flink-storage-key]
                                       [--flink-storage-uri]
                                       [--force-string {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--history-server-cpu]
                                       [--history-server-memory]
                                       [--identity-list]
                                       [--ids]
                                       [--job-manager-cpu]
                                       [--job-manager-memory]
                                       [--job-spec]
                                       [--kafka-profile]
                                       [--key-vault-id]
                                       [--llap-profile]
                                       [--loadbased-config-max-nodes]
                                       [--loadbased-config-min-nodes]
                                       [--loadbased-config-poll-interval]
                                       [--loadbased-config-scaling-rules]
                                       [--no-wait {0, 1, f, false, n, no, t, true, y, yes}]
                                       [--nodes]
                                       [--num-replicas]
                                       [--oss-version]
                                       [--ranger-plugin-profile]
                                       [--ranger-profile]
                                       [--remove]
                                       [--resource-group]
                                       [--schedule-based-config-default-count]
                                       [--schedule-based-config-schedule]
                                       [--schedule-based-config-time-zone]
                                       [--script-action-profiles]
                                       [--secret-reference]
                                       [--service-configs]
                                       [--set]
                                       [--spark-hive-catalog-db-name]
                                       [--spark-hive-catalog-db-password-secret]
                                       [--spark-hive-catalog-db-server-name]
                                       [--spark-hive-catalog-db-user-name]
                                       [--spark-hive-catalog-key-vault-id]
                                       [--spark-hive-catalog-thrift-url]
                                       [--spark-storage-url]
                                       [--ssh-profile-count]
                                       [--stub-profile]
                                       [--subscription]
                                       [--tags]
                                       [--task-manager-cpu]
                                       [--task-manager-memory]
                                       [--trino-hive-catalog]
                                       [--trino-plugins-spec]
                                       [--trino-profile-user-plugins-telemetry-spec]
                                       [--user-plugins-spec]
                                       [--vm-size]
                                       [--worker-debug-port]
                                       [--worker-debug-suspend {0, 1, f, false, n, no, t, true, y, yes}]
  examples:
  - summary: |-
      Update a cluster service-config.
    syntax: az hdinsight-on-aks cluster update -n {clusterName} --cluster-pool-name {poolName} -g {RG} -service-configs {"[{service-name:yarn-service,configs:[{component:hadoop-config-client,files:[{file-name:yarn-site.xml,values:{yarn.nodemanager.resource.memory-mb:33333}}]}]}]"}
  optionalParameters:
  - name: --add
    summary: |-
      Add an object to a list of objects by specifying a path and key value pairs.  Example: `--add property.listProperty <key=value, string or JSON string>`.
  - name: --application-log-std-error-enabled --enable-log-std-error
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if application standard error is enabled, otherwise false.
  - name: --application-log-std-out-enabled --enable-log-std-out
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if application standard out is enabled, otherwise false.
  - name: --assigned-identity-client-id --msi-client-id
    summary: |-
      ClientId of the MSI.
  - name: --assigned-identity-id --msi-id
    summary: |-
      ResourceId of the MSI.
  - name: --assigned-identity-object-id --msi-object-id
    summary: |-
      ObjectId of the MSI.
  - name: --authorization-group-id
    summary: |-
      AAD group Ids authorized for data plane access.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --authorization-user-id
    summary: |-
      AAD user Ids authorized for data plane access.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --autoscale-profile-graceful-decommission-timeout --decommission-time
    summary: |-
      This property is for graceful decommission timeout; It has a default setting of 3600 seconds before forced shutdown takes place. This is the maximal time to wait for running containers and applications to complete before transition a DECOMMISSIONING node into DECOMMISSIONED. The default value is 3600 seconds. Negative value (like -1) is handled as infinite timeout.
  - name: --autoscale-profile-type
    parameterValueGroup: "LoadBased, ScheduleBased"
    summary: |-
      User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.
  - name: --availability-zones
    summary: |-
      The list of Availability zones to use for AKS VMSS nodes.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --cluster-name --name -n
    summary: |-
      The name of the HDInsight cluster.
  - name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - name: --cluster-version
    summary: |-
      Version with 3/4 part.
  - name: --cooldown-period --loadbased-config-cooldown-period
    summary: |-
      This is a cool down period, this is a time period in seconds, which determines the amount of time that must elapse between a scaling activity started by a rule and the start of the next scaling activity, regardless of the rule that triggers it. The default value is 300 seconds.
  - name: --coord-debug-port --coordinator-debug-port
    summary: |-
      The flag that if enable debug or not. Default: 8008.
  - name: --coord-debug-suspend --coordinator-debug-suspend
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if suspend debug or not. Default: false.
  - name: --coordinator-debug-enabled --enable-coord-debug
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.
  - name: --coordinator-high-availability-enabled --enable-coord-ha
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.
  - name: --db-connection-authentication-mode --spark-db-auth-mode
    parameterValueGroup: "IdentityAuth, SqlAuth"
    summary: |-
      The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization.
  - name: --deployment-mode
    parameterValueGroup: "Application, Session"
    summary: |-
      A string property that indicates the deployment mode of Flink cluster. It can have one of the following enum values => Application, Session. Default value is Session.
  - name: --enable-autoscale
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      This indicates whether auto scale is enabled on HDInsight on AKS cluster.
  - name: --enable-la-metrics --log-analytic-profile-metrics-enabled
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if metrics are enabled, otherwise false.
  - name: --enable-log-analytics
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      True if log analytics is enabled for the cluster, otherwise false.
  - name: --enable-prometheu
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Enable Prometheus for cluster or not.
  - name: --enable-worker-debug
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if trino cluster enable debug or not. Default: false.
  - name: --flink-db-auth-mode --metastore-db-connection-authentication-mode
    parameterValueGroup: "IdentityAuth, SqlAuth"
    summary: |-
      The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization.
  - name: --flink-hive-catalog-db-connection-password-secret --flink-hive-db-secret
    summary: |-
      Secret reference name from secretsProfile.secrets containing password for database connection.
  - name: --flink-hive-catalog-db-connection-url --flink-hive-db-url
    summary: |-
      Connection string for hive metastore database.
  - name: --flink-hive-catalog-db-connection-user-name --flink-hive-db-user
    summary: |-
      User name for database connection.
  - name: --flink-storage-key
    summary: |-
      Storage key is only required for wasb(s) storage.
  - name: --flink-storage-uri
    summary: |-
      Storage account uri which is used for savepoint and checkpoint state.
  - name: --force-string
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      When using 'set' or 'add', preserve string literals instead of attempting to convert to JSON.
  - name: --history-server-cpu
    summary: |-
      History server CPU count.
  - name: --history-server-memory
    summary: |-
      History server memory size.
  - name: --identity-list
    summary: |-
      The list of managed identity.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --job-manager-cpu
    summary: |-
      Job manager CPU count.
  - name: --job-manager-memory
    summary: |-
      Job manager memory size.
  - name: --job-spec
    summary: |-
      Job specifications for flink clusters in application deployment mode. The specification is immutable even if job properties are changed by calling the RunJob API, please use the ListJob API to get the latest job information.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --kafka-profile
    summary: |-
      Kafka cluster profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --key-vault-id
    summary: |-
      Name of the user Key Vault where all the cluster specific user secrets are stored.
  - name: --llap-profile
    summary: |-
      LLAP cluster profile.  Support json-file and yaml-file.
  - name: --loadbased-config-max-nodes --loadbased-max-nodes
    summary: |-
      User needs to set the maximum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.
  - name: --loadbased-config-min-nodes --loadbased-min-nodes
    summary: |-
      User needs to set the minimum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.
  - name: --loadbased-config-poll-interval --loadbased-interval
    summary: |-
      User can specify the poll interval, this is the time period (in seconds) after which scaling metrics are polled for triggering a scaling operation.
  - name: --loadbased-config-scaling-rules --loadbased-rules
    summary: |-
      The scaling rules.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --no-wait
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      Do not wait for the long-running operation to finish.
  - name: --nodes
    summary: |-
      The nodes definitions.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --num-replicas
    summary: |-
      The number of task managers.
  - name: --oss-version
    summary: |-
      Version with three part.
  - name: --ranger-plugin-profile
    summary: |-
      Cluster Ranger plugin profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --ranger-profile
    summary: |-
      The ranger cluster profile.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --remove
    summary: |-
      Remove a property or an element from a list.  Example: `--remove property.list <indexToRemove>` OR `--remove propertyToRemove`.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --schedule-based-config-default-count --schedule-default-count
    summary: |-
      Setting default node count of current schedule configuration. Default node count specifies the number of nodes which are default when an specified scaling operation is executed (scale up/scale down).
  - name: --schedule-based-config-schedule --schedule-schedules
    summary: |-
      This specifies the schedules where scheduled based Autoscale to be enabled, the user has a choice to set multiple rules within the schedule across days and times (start/end).  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --schedule-based-config-time-zone --schedule-time-zone
    summary: |-
      User has to specify the timezone on which the schedule has to be set for schedule based autoscale configuration.
  - name: --script-action-profiles
    summary: |-
      The script action profile list.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --secret-reference
    summary: |-
      Properties of Key Vault secret.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --service-configs --service-configs-profiles
    summary: |-
      The service configs profiles.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --set
    summary: |-
      Update an object by specifying a property path and value to set.  Example: `--set property1.property2=<value>`.
  - name: --spark-hive-catalog-db-name --spark-hive-db-name
    summary: |-
      The database name.
  - name: --spark-hive-catalog-db-password-secret --spark-hive-db-secret
    summary: |-
      The secret name which contains the database user password.
  - name: --spark-hive-catalog-db-server-name --spark-hive-db-server
    summary: |-
      The database server host.
  - name: --spark-hive-catalog-db-user-name --spark-hive-db-user
    summary: |-
      The database user name.
  - name: --spark-hive-catalog-key-vault-id --spark-hive-kv-id
    summary: |-
      The key vault resource id.
  - name: --spark-hive-catalog-thrift-url --spark-hive-thrift-url
    summary: |-
      The thrift url.
  - name: --spark-storage-url
    summary: |-
      The default storage URL.
  - name: --ssh-profile-count
    summary: |-
      Number of ssh pods per cluster.
  - name: --stub-profile
    summary: |-
      Stub cluster profile.  Support json-file and yaml-file.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --tags
    summary: |-
      Resource tags.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --task-manager-cpu
    summary: |-
      Task manager CPU count.
  - name: --task-manager-memory
    summary: |-
      The task manager memory size.
  - name: --trino-hive-catalog
    summary: |-
      Hive catalog options.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --trino-plugins-spec --trino-profile-user-plugins-plugin-spec
    summary: |-
      Trino user plugins spec  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --trino-profile-user-plugins-telemetry-spec --trino-telemetry-spec
    summary: |-
      Trino user telemetry spec.  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --user-plugins-spec
    summary: |-
      Spark user plugins spec  Support shorthand-syntax, json-file and yaml-file. Try "??" to show more.
  - name: --vm-size
    summary: |-
      The virtual machine SKU.
  - name: --worker-debug-port
    summary: |-
      The debug port. Default: 8008.
  - name: --worker-debug-suspend
    parameterValueGroup: "0, 1, f, false, n, no, t, true, y, yes"
    summary: |-
      The flag that if trino cluster suspend debug or not. Default: false.
- uid: az_hdinsight-on-aks_cluster_wait
  name: az hdinsight-on-aks cluster wait
  summary: |-
    Place the CLI in a waiting state until a condition is met.
  status: Preview
  isPreview: true
  previewOrExperimentalInfo: "Command group 'az hdinsight-on-aks cluster' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus"
  sourceType: Extension
  syntax: >-
    az hdinsight-on-aks cluster wait [--cluster-name]
                                     [--cluster-pool-name]
                                     [--created]
                                     [--custom]
                                     [--deleted]
                                     [--exists]
                                     [--ids]
                                     [--interval]
                                     [--resource-group]
                                     [--subscription]
                                     [--timeout]
                                     [--updated]
  optionalParameters:
  - name: --cluster-name --name -n
    summary: |-
      The name of the HDInsight cluster.
  - name: --cluster-pool-name
    summary: |-
      The name of the cluster pool.
  - name: --created
    defaultValue: "False"
    summary: |-
      Wait until created with 'provisioningState' at 'Succeeded'.
  - name: --custom
    summary: |-
      Wait until the condition satisfies a custom JMESPath query. E.g. provisioningState!='InProgress', instanceView.statuses[?code=='PowerState/running'].
  - name: --deleted
    defaultValue: "False"
    summary: |-
      Wait until deleted.
  - name: --exists
    defaultValue: "False"
    summary: |-
      Wait until the resource exists.
  - name: --ids
    summary: |-
      One or more resource IDs (space-delimited). It should be a complete resource ID containing all information of 'Resource Id' arguments. You should provide either --ids or other 'Resource Id' arguments.
  - name: --interval
    defaultValue: "30"
    summary: |-
      Polling interval in seconds.
  - name: --resource-group -g
    summary: |-
      Name of resource group. You can configure the default group using `az configure --defaults group=<name>`.
  - name: --subscription
    summary: |-
      Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
  - name: --timeout
    defaultValue: "3600"
    summary: |-
      Maximum wait in seconds.
  - name: --updated
    defaultValue: "False"
    summary: |-
      Wait until updated with provisioningState at 'Succeeded'.
commands:
- az_hdinsight-on-aks_cluster_create
- az_hdinsight-on-aks_cluster_delete
- az_hdinsight-on-aks_cluster_instance-view
- az_hdinsight-on-aks_cluster_instance-view_list
- az_hdinsight-on-aks_cluster_instance-view_show
- az_hdinsight-on-aks_cluster_job
- az_hdinsight-on-aks_cluster_job_list
- az_hdinsight-on-aks_cluster_job_run
- az_hdinsight-on-aks_cluster_library
- az_hdinsight-on-aks_cluster_library_list
- az_hdinsight-on-aks_cluster_library_manage
- az_hdinsight-on-aks_cluster_list
- az_hdinsight-on-aks_cluster_list-service-config
- az_hdinsight-on-aks_cluster_node-profile
- az_hdinsight-on-aks_cluster_node-profile_create
- az_hdinsight-on-aks_cluster_resize
- az_hdinsight-on-aks_cluster_show
- az_hdinsight-on-aks_cluster_update
- az_hdinsight-on-aks_cluster_upgrade
- az_hdinsight-on-aks_cluster_upgrade_history
- az_hdinsight-on-aks_cluster_upgrade_list
- az_hdinsight-on-aks_cluster_upgrade_rollback
- az_hdinsight-on-aks_cluster_upgrade_run
- az_hdinsight-on-aks_cluster_wait
globalParameters:
- name: --debug
  summary: |-
    Increase logging verbosity to show all debug logs.
- name: --help -h
  summary: |-
    Show this help message and exit.
- name: --only-show-errors
  summary: |-
    Only show errors, suppressing warnings.
- name: --output -o
  defaultValue: "json"
  parameterValueGroup: "json, jsonc, none, table, tsv, yaml, yamlc"
  summary: |-
    Output format.
- name: --query
  summary: |-
    JMESPath query string. See <a href="http://jmespath.org/">http://jmespath.org/</a> for more information and examples.
- name: --subscription
  summary: |-
    Name or ID of subscription. You can configure the default subscription using `az account set -s NAME_OR_ID`.
- name: --verbose
  summary: |-
    Increase logging verbosity. Use --debug for full debug logs.
metadata:
  description: Cluster operations.
